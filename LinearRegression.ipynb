{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear methods assume that there is a linear relationship between the features and the target/label, that is\n",
    "$$y = w_1 x_1 + w_2 x_2 + w_x x_k + b$$\n",
    "where $y$ - target (what we want to predict), $x_i$ - feature of $x$, $w_i$ - weight of $i$-th feature, $b$ - bias."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Formula\n",
    "$x_i$ and $y_i$ is $x$ and $y$ coordinate of $i$-th point\n",
    "$n$ is length of input\n",
    "$$\n",
    "intercept = \\frac{ \\sum{x_i^2} \\cdot \\sum{y_i} - \\sum{x_i} \\cdot \\sum{x_i y_i}  }{n \\sum{x_i^2} - (\\sum{x_i})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "slope = \\frac{n \\sum{x_i y_i} - \\sum{x_i} \\cdot  \\sum{y_i}}{n \\sum{x_i^2} - (\\sum{x_i})^2}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fitted = False\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, k = X.shape\n",
    "\n",
    "        X_train = X\n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "\n",
    "        self.w = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y\n",
    "\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def fitted(self):\n",
    "        return self.fitted\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.fitted:\n",
    "            return \"Not fitted\"\n",
    "        n, k = X.shape\n",
    "        if self.fit_intercept:\n",
    "            X_train = np.hstack((X, np.ones((n, 1))))\n",
    "\n",
    "        y_pred = X_train @ self.w\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class MyGradientLinearRegression(LinearRegression):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, y, lr=0.01, max_iter=100):\n",
    "        n, k = X.shape\n",
    "\n",
    "        if self.w is None:\n",
    "            self.w = np.random.randn(k + 1 if self.fit_intercept else k)\n",
    "\n",
    "        X_train = np.hstack((X, np.ones((n, 1)))) if self.fit_intercept else X\n",
    "\n",
    "        self.losses = []\n",
    "\n",
    "        for iter_num in range(max_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            self.losses.append(mean_squared_error(y_pred, y))\n",
    "\n",
    "            grad = self._calc_gradient(X_train, y, y_pred)\n",
    "\n",
    "            assert grad.shape == self.w.shape, f\"gradient shape {grad.shape} is not equal weight shape {self.w.shape}\"\n",
    "            self.w -= lr * grad\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _calc_gradient(self, X, y, y_pred):\n",
    "        grad = 2 * (y_pred - y)[:, np.newaxis] * X\n",
    "        grad = grad.mean(axis=0)\n",
    "        return grad\n",
    "\n",
    "    def get_losses(self):\n",
    "        return self.losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MySGDLinearRegression(MyGradientLinearRegression):\n",
    "    def __init__(self, n_sample=10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = None\n",
    "        self.n_sample = n_sample\n",
    "\n",
    "    def _calc_gradient(self, X, y, y_pred):\n",
    "        inds = np.random.choice(np.arange(X.shape[0]), size=self.n_sample, replace=False)\n",
    "\n",
    "        grad = 2 * (y_pred[inds] - y[inds])[:, np.newaxis] * X[inds]\n",
    "        grad = grad.mean(axis=0)\n",
    "\n",
    "        return grad"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
